{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023bb7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yu-sun00/opt/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/reuters.py:113: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/yu-sun00/opt/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/reuters.py:114: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 04:16:42.996752: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-29 04:16:42.997173: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7859 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "7859/7859 [==============================] - 12s 1ms/sample - loss: 1.3084 - accuracy: 0.7207 - val_loss: 0.9185 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "7859/7859 [==============================] - 11s 1ms/sample - loss: 0.5029 - accuracy: 0.8871 - val_loss: 0.8351 - val_accuracy: 0.8103\n",
      "Epoch 3/5\n",
      "7859/7859 [==============================] - 11s 1ms/sample - loss: 0.2815 - accuracy: 0.9366 - val_loss: 0.8735 - val_accuracy: 0.8085\n",
      "Epoch 4/5\n",
      "7859/7859 [==============================] - 12s 1ms/sample - loss: 0.2239 - accuracy: 0.9499 - val_loss: 0.9005 - val_accuracy: 0.8097\n",
      "Epoch 5/5\n",
      "7859/7859 [==============================] - 12s 2ms/sample - loss: 0.1931 - accuracy: 0.9538 - val_loss: 0.9558 - val_accuracy: 0.8074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f97728512e8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(test_split=0.3)\n",
    "\n",
    "# 단어 인덱스로 변환된 데이터를 텍스트로 변환하기 위해 필요한 매핑 로드\n",
    "word_index = reuters.get_word_index()\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "index_to_word[0] = '<PAD>'\n",
    "index_to_word[1] = '<START>'\n",
    "index_to_word[2] = '<UNK>'\n",
    "ㅌㅈ\n",
    "# 데이터 전처리\n",
    "num_classes = np.max(y_train) + 1\n",
    "max_words = 10000  # 상위 10,000개의 단어만 사용\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# 모델 구축\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 모델 훈련\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7724f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
